= Creating a custom integration test

In {ProductName}, you can create your own integration tests to run on all components of a given application before they are deployed. 

.Procedure

To create any custom test, complete the following steps:

. In your preferred IDE, create a Tekton pipeline in a `.yaml` file. 
. Within that pipeline, create tasks, which define the actual steps of the test that {ProductName} executes against images before deploying them.
. Commit the `.yaml` file to a GitHub repo and add it as an integration test in {ProductName}.

.Procedure with example

To create a custom test that prints “Hello world!”, complete the following steps:

. In your preferred IDE, create a new `.yaml` file, with a name of your choosing.
. Define a new Tekton pipeline. The following example is the beginning of a pipeline that prints “Hello world!”.

+
Example pipeline file:

+
[source]
----
kind: Pipeline
apiVersion: tekton.dev/v1beta1
metadata:
  name: example-pipeline
spec:
  params:
  - name: username
    default: world 
  tasks: 
----

. In the `.pipeline.spec` path, declare a new task. For any valid task, the fields in the following example are all required, except `params`. 

+
Example task declaration:

+
[source]
----
tasks:
  - name: task-1
    params:
    - name: username
      value: $(params.username)
    taskSpec:
      params:
      - name: username
      steps:
      - image: alpine:3.15
        script: |
          echo "hello $(params.username)"

----

. Save the `.yaml` file. 
.. If you haven’t already, commit this file to a GitHub repository that {ProductName} can access.

+
Complete example file:

+
[source]
----
kind: Pipeline
apiVersion: tekton.dev/v1beta1
metadata:
  name: example-pipeline
spec:
  params:
  - name: username
    default: world 
  tasks:
  - name: task-1
    params:
    - name: username
      value: $(params.username)
    taskSpec:
      params:
      - name: username
      steps:
      - image: alpine:3.15
        script: |
          echo "Hello $(params.username)!" 
----

. Add your new custom test as an integration test in {ProductName}.
.. For additional instructions on adding an integration test, see this document: xref:how-to-guides/testing_applications/proc_adding_an_integration_test.adoc[Adding an integration test].

.Data injected into the PipelineRun of the integration test

When you create a custom integration test, {ProductName} automatically adds certain parameters and labels to the PipelineRun of the integration test. This section explains what those parameters and labels are, and how they can help you.

Parameters:

* *`SNAPSHOT`*: contains the xref:../../glossary/index.adoc#_snapshot[snapshot] of the whole application as a JSON string. This JSON string provides useful information about the test, such as which components {ProductName} is testing, and what git repository and commit {ProductName} is using to build those components. For information about snapshot JSON string, see link:https://github.com/redhat-appstudio/integration-examples/blob/main/examples/snapshot_json_string_example[an example snapshot json string]
* *`NAMESPACE`*:  adds the `namespace` parameter to indicate which namespace it uses for deployment only if your integration test specifies that {ProductName} should deploy a snapshot to an ephemeral environment during testing. This parameter can help you query Kubernetes resources that are deployed in the test environment, such as routes, deployments, and pods. 

Labels:

* *`appstudio.openshift.io/application`*: contains the name of the application
* *`appstudio.openshift.io/component`*: contains the name of the component
* *`appstudio.openshift.io/snapshot`*: contains the name of the snapshot
* `test.appstudio.openshift.io/optional`: contains the optional flag, which specifies whether or not components must pass the integration test before deployment.  
* `test.appstudio.openshift.io/scenario`: contains the name of the integration test (this label ends with "scenario," because each test is technically a custom resource called an `IntegrationTestScenario`). 

.Verification

After adding the integration test to an application, you need to trigger a new build of its components to make {ProductName} run the integration test. Make a commit to the GitHub repositories of your components to trigger a new build.

When the new build is finished, complete the following steps in the {ProductName} console:

. Go to the *Integration tests* tab and select the highlighted name of your test.
. Go to the *Pipeline runs* tab of that test and select the most recent run.
. On the *Details* page, see if the test succeeded for that component. Select the other tabs to view more details.
.. If you used our example script, switch to the *Logs* tab and verify that the test printed “Hello world!”.  
